services:
  db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: prod_db
    volumes:
      - db_data:/var/lib/postgresql/data

  backend:
    build:
      context: ./stackoverflow_be
      dockerfile: Dockerfile
    ports:
      - "4000:4000"
    environment:
      MIX_ENV: prod
      DATABASE_URL: ecto://postgres:postgres@db/prod_db
      SECRET_KEY_BASE: your_prod_secret
      LLM_API_URL: http://llm:11434/api/generate
    depends_on:
      - db
      - llm

  frontend:
    build:
      context: ./stackoverflow_fe
      dockerfile: Dockerfile
    ports:
      - "80:80"
    depends_on:
      - backend

  llm:
    image: ollama/ollama
    container_name: local_llm
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    command: >
      sh -c "
        /bin/ollama serve &
        sleep 2 &&
        ollama pull ${LLM_MODEL:-tinyllama} &&
        tail -f /dev/null"
    restart: unless-stopped

volumes:
  db_data:
  ollama_models:
